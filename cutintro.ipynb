{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import lzma\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.max_rows = 1000\n",
    "#plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-paper')\n",
    "mpl.rcParams['axes.linewidth'] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = \"latest_results.json.xz\"\n",
    "\n",
    "data = None\n",
    "if file.endswith('.xz'): file = lzma.open(file, 'rt')\n",
    "data = pd.read_json(file)\n",
    "data = data.sort_values(['file', 'method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data.method != 'reforest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding a column for the database\n",
    "data['db'] = -1 + \\\n",
    "    (0+1)*data.file.str.endswith(')') + \\\n",
    "    (1+1)*data.file.str.contains('/Prover9--') + \\\n",
    "    (2+1)*data.file.str.contains('/Vampire---4.0') + \\\n",
    "    (3+1)*data.file.str.contains('/leanCoP--') + \\\n",
    "    (4+1)*data.file.str.contains('/QF_UF/')\n",
    "    \n",
    "data['status'] = data.status.fillna(\"timeout_\" + data.phase)\n",
    "\n",
    "data['is_smaller'] = (data.status=='ok') & (data.ehs_lkinf < data.hs_lkinf)\n",
    "data['is_larger'] = (data.status=='ok') & (data.ehs_lkinf >= data.hs_lkinf)\n",
    "data['is_trivial'] = data.status.str.endswith('termset_trivial')\n",
    "data['is_uncompressible'] = data.status.str.endswith('uncompressible')\n",
    "data['is_timeout'] = data.status.str.startswith('timeout')\n",
    "data['is_error'] = ~data.is_smaller & ~data.is_larger & ~data.is_trivial & ~data.is_uncompressible & ~data.is_timeout\n",
    "\n",
    "data['tstp_cat'] = data.file.str.extract('/([A-Z]{3,3})/', expand=False)\n",
    "data['is_tstp'] = data.tstp_cat.notnull()\n",
    "\n",
    "data['compression_ratio'] = data.termset/data.grammar_size\n",
    "data['inv_compression_ratio'] = data.grammar_size/data.termset\n",
    "\n",
    "data['lk_cmp_ratio'] = data.ehs_lkinf/data.hs_lkinf\n",
    "\n",
    "data['has_sol'] = data.time_beausol>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Other exceptions (aka bugs to hunt)\n",
    "\n",
    "data_other_exp = data[(data.status == 'cutintro_other_exception')]\n",
    "data_other_exp[['method', 'file', 'status']].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods = sorted(set(data.method.dropna()))\n",
    "\n",
    "dbs = {\n",
    "    0: 'Proof examples',\n",
    "    1: 'Prover9',\n",
    "    2: 'Vampire',\n",
    "    3: 'LeanCoP',\n",
    "    4: 'VeriT',\n",
    "}\n",
    "\n",
    "dbs = { i: dbs[i] for i in dbs.keys() if i in data.db.values }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"=== Number of tests per database and method:\\n\")\n",
    "\n",
    "#for dbi, dbname in dbs.items():\n",
    "#    for method in methods:\n",
    "#        print(\"{0} - {1}: {2}\".format(dbname, method,\n",
    "#                                     data[(data.method==method) & (data.db==dbi)].shape[0]))\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = set(data.status.values)\n",
    "status_colors = {}\n",
    "for s in states:\n",
    "    if s == 'ok':\n",
    "        c = 'green'\n",
    "    elif s == 'cutintro_uncompressible':\n",
    "        c = 'yellow'\n",
    "    elif s == 'cutintro_termset_trivial':\n",
    "        c = 'gold'\n",
    "    elif 'timeout' in s:\n",
    "        c = plt.cm.Blues(hash(s)/2**65+0.5)\n",
    "    elif s.endswith('exception'):\n",
    "        c = plt.cm.Reds(hash(s)/2**65+0.5)\n",
    "    else:\n",
    "        c = plt.cm.Greys(hash(s)/2**65+0.5)\n",
    "    status_colors[s] = c\n",
    "\n",
    "def plot_status(d, legend=True, **kwargs):\n",
    "    plt.axis('equal')\n",
    "    d.plot(kind='pie', autopct='%1.1f%%',\n",
    "                        colors=[status_colors[s] for s in d.index], **kwargs) \\\n",
    "        .set_ylabel('')\n",
    "    if legend: plt.legend(d.index, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_status(data.groupby('status').size(), figsize=(14,12), title='Return status: full set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xsize, ysize = len(dbs.items()), len(methods)\n",
    "plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "plt.suptitle('Status per method and db', fontsize=25)\n",
    "for j, (dbi, db) in enumerate(dbs.items()):\n",
    "    for i, method in enumerate(methods):\n",
    "        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "        subdata = data[(data.db==dbi) & (data.method==method)].groupby('status').size()\n",
    "        plot_status(subdata, title='{0}\\n{1}'.format(db,method), labels=None, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timecols = ['time_grammar', 'time_minsol', 'time_prcons', 'time_cleanproof']\n",
    "#plt.axis('equal')\n",
    "#data[timecols].mean().plot(kind='pie', figsize=(12,12), autopct='%1.1f%%',\n",
    "#                           title='Time: full set', legend=True).set_ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xsize, ysize = len(dbs.items()), len(methods)\n",
    "#plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "#plt.suptitle('Time consumption per method and db', fontsize=25)\n",
    "#for i, method in enumerate(methods):\n",
    "#    for j, (dbi, db) in enumerate(dbs.items()):\n",
    "#        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "#        plt.axis('equal')\n",
    "#        data[(data.db==dbi) & (data.method==method)][timecols].mean() \\\n",
    "#            .plot(kind='pie', autopct='%1.1f%%', labels=None,\n",
    "#                  title='{0}\\n{1}'.format(db,method)).set_ylabel('')\n",
    "#plt.legend(timecols, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xsize, ysize = len(dbs.items()), len(methods)\n",
    "#plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "#plt.suptitle('Time consumption per method and db, state==ok', fontsize=25)\n",
    "#for i, method in enumerate(methods):\n",
    "#    for j, (dbi, db) in enumerate(dbs.items()):\n",
    "#        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "#        plt.axis('equal')\n",
    "#        ax = data[(data.db==dbi) & (data.method==method) & (data.status=='ok')][timecols].mean() \\\n",
    "#            .plot(kind='pie', autopct='%1.1f%%', labels=None,\n",
    "#                  title='{0}\\n{1}'.format(db,method))\n",
    "#        ax.set_ylabel('')\n",
    "#plt.legend(timecols, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different grammar sizes between different methods: one cut with one quantifier\n",
    "data_dtable = data[(data.method == '1_dtable') & data.grammar_size]\n",
    "data_maxsat = data[(data.method == '1_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = pd.merge(data_dtable, data_maxsat, on=['file'], suffixes=('_dtable', '_maxsat'))\n",
    "merged[merged.grammar_size_dtable != merged.grammar_size_maxsat] \\\n",
    "    [['file', 'grammar_size_dtable', 'grammar_size_maxsat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different grammar sizes between different methods: one cut with multiple quantifiers\n",
    "data_dtable = data[(data.method == 'many_dtable') & data.grammar_size]\n",
    "data_maxsat = data[(data.method == '2_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = pd.merge(data_dtable, data_maxsat, on=['file'], suffixes=('_dtable', '_maxsat'))\n",
    "merged[merged.grammar_size_dtable != merged.grammar_size_maxsat] \\\n",
    "    [['file', 'grammar_size_dtable', 'grammar_size_maxsat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Better compression with 2x2 quantifiers than 1x2 quantifiers or 2x1 quantifiers\n",
    "data_1x2 = data[(data.method == '2_maxsat') & data.grammar_size]\n",
    "data_2x1 = data[(data.method == '1_1_maxsat') & data.grammar_size]\n",
    "data_2x2 = data[(data.method == '2_2_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = data_1x2.merge(data_2x1, on='file', suffixes=('_1x2', '_2x1')) \\\n",
    "    .merge(data_2x2, on='file')\n",
    "merged[(merged.grammar_size < merged.grammar_size_1x2) & (merged.grammar_size < merged.grammar_size_2x1)] \\\n",
    "    [['file', 'grammar_size', 'grammar_size_2x1', 'grammar_size_1x2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['is_ok'] = data['status']=='ok'\n",
    "summary = (data[(data.termset<65)&data.is_tstp&(data.method=='many_dtable_ss')].groupby('termset').sum() \\\n",
    "    [['is_trivial', 'is_uncompressible', 'is_ok', 'is_timeout']] * 1)\n",
    "summary.columns = ['trivial', 'uncompressible', 'lemma generated', 'timeout']\n",
    "summary.plot(kind='area', figsize=(5.5,4), ylim=(0,5500),\n",
    "          title='Status by termset size for the delta-table with many variables',\n",
    "          color=['gold', 'yellow', 'lime', 'lightblue', 'tomato'])\n",
    "plt.ylabel(\"Number of proofs\")\n",
    "plt.xlabel(\"Termset size\")\n",
    "plt.savefig('status_by_termset.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proofs with good compression of EHS/HS\n",
    "data[(data.ehs_lkinf/data.hs_lkinf < 0.2)].sort_values('lk_cmp_ratio') \\\n",
    "    [['file', 'method', 'ehs_lkinf', 'hs_lkinf', 'lkinf_input', 'beausol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proofs with blowup\n",
    "data[data.ehs_lkinf > 5*data.hs_lkinf] \\\n",
    "    [['file', 'method', 'ehs_lkinf', 'hs_lkinf', 'lkinf_input']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cactus plot for grammar finding methods\n",
    "\n",
    "plt.figure(figsize=(5.5,3))\n",
    "\n",
    "tstp_dataset = \\\n",
    "    (data.grammar_size>0)& \\\n",
    "    data.beausol& \\\n",
    "    data.is_tstp\n",
    "for marker, method in zip(\"*sov^<>1\", sorted(set(data[tstp_dataset].method),\n",
    "                     key = lambda m: len(data[tstp_dataset&(data.method==m)&(data.time_grammar<5000)]))):\n",
    "    plt.plot(\n",
    "        data[(data.method==method)&tstp_dataset].\n",
    "            time_grammar.sort_values().values / 1000,\n",
    "        label=method,\n",
    "        marker=marker, markevery=0.1)\n",
    "\n",
    "virtual_best = data[tstp_dataset].groupby('file').time_grammar.min()\n",
    "plt.plot(virtual_best.sort_values().values / 1000, label='virtual best', color='orange',\n",
    "         marker='D', markevery=0.1)\n",
    "\n",
    "plt.xlabel('Number of grammars that lead to a non-trivial lemma')\n",
    "plt.ylabel('CPU runtime (seconds)')\n",
    "plt.ylim(0,5)\n",
    "plt.xlim(0,12000)\n",
    "plt.legend(loc='upper right', framealpha=0.7)\n",
    "plt.savefig('grammar_finding_cactus.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[(data.beausol_scomp < 100) &\n",
    "     (data.beausol_lcomp > 3) &\n",
    "     (data.beausol_scomp > 1) &\n",
    "     (data.time_total > 30000) &\n",
    "     data.is_tstp &\n",
    "     ~data.file.str.contains('SY')] \\\n",
    "    .sort_values('beausol_scomp')[['file', 'method', 'beausol', 'time_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5,3))\n",
    "tstp_success = data[data.is_tstp&data.beausol]\n",
    "(tstp_success.minsol_scomp/tstp_success.cansol_scomp).plot.kde(label='minimized', marker='s', markevery=0.1)\n",
    "(tstp_success.beausol_scomp/tstp_success.cansol_scomp).plot.kde(label='beautified', marker='o', markevery=0.1)\n",
    "plt.legend()\n",
    "plt.xlim(0,1)\n",
    "plt.ylabel('Estimated density')\n",
    "plt.xlabel('Ratio of symbolic complexity compared to canonical solution')\n",
    "plt.savefig('improvement_comp_density.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Added productions during beautification\n",
    "tstp_success = data[data.is_tstp&data.beausol]\n",
    "(tstp_success.beaugrammar_size-tstp_success.grammar_size).describe(percentiles = [.25, .5, .75, .80, .85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "tstp_ok = data[data.is_tstp&(data.status=='ok')&data.ehs_lkinf]\n",
    "(np.log(tstp_ok.ehs_lkinf/tstp_ok.hs_lkinf)/np.log(10)).plot.hist(label='proof of EHS', bins=100)\n",
    "plt.legend()\n",
    "plt.ylabel('Number of proofs')\n",
    "plt.xlabel('Logarithmic ratio of number of inferences of proof of EHS compared to proof of HS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.is_tstp&data.beausol&(data.method!='reforest')].plot.scatter('termset', 'compression_ratio',\n",
    "                          alpha=0.2, figsize=(14,8))\n",
    "plt.xlim(0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "data[data.is_tstp&data.beausol&data.is_tstp&(data.termset_trivial==False)].inv_compression_ratio.plot.hist(bins=100)\n",
    "plt.xlabel('Compression ratio (size of term set / size of grammar)')\n",
    "plt.xlim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of proofs in TSTP library\n",
    "num_tstp = len(set(data[data.is_tstp].file)); num_tstp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of proofs we can parse\n",
    "num_tstp_parsed = len(set(data[data.is_tstp&data.termset].file)); num_tstp_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of trivial termsets\n",
    "num_trivial = len(set(data[data.is_tstp&data.termset_trivial].file)); num_trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of non-trivial termsets\n",
    "num_nontrivial = len(set(data[data.is_tstp&(data.termset_trivial==False)].file)); num_nontrivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of grammars generated\n",
    "num_grammar_gen = len(set(data[data.is_tstp&data.grammar_size].file)); num_grammar_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of lemmas generated\n",
    "num_lemmas_gen = len(set(data[data.is_tstp&data.beausol].file)); num_lemmas_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solutions for trivial termsets\n",
    "data[data.is_tstp &\n",
    "     data.termset_trivial &\n",
    "     (data.grammar_size>0) &\n",
    "     (data.beausol_scomp<10) &\n",
    "     (data.beausol_scomp>1)\n",
    "    ][['file', 'beausol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of proofs with trivial termsets where we found a grammar\n",
    "len(set(data[data.is_tstp&data.termset_trivial&(data.grammar_size>0)].file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Size of canonical solution vs grammar size\n",
    "tstp_success = data[data.is_tstp&data.beausol]\n",
    "tstp_success.plot.scatter('cansol_lcomp', 'grammar_size', figsize=(14,8), alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.status=='cutintro_noncovering_grammar'][['file','method']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(data[data.time_total>0].time_total/1000).plot.hist(xlim=(0,60), bins=100, figsize=(5.5,3))\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel('Number of proofs')\n",
    "plt.savefig('timedist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.lk_cmp_ratio<10].lk_cmp_ratio.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.lk_cmp_ratio<1].plot.scatter('lk_cmp_ratio', 'inv_compression_ratio', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.lk_cmp_ratio<1].plot.scatter('termset', 'lk_cmp_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(5.5,3))\n",
    "data[data.is_tstp&data.has_sol].plot.scatter('termset', 'inv_compression_ratio', ax=axes[0],\n",
    "                                             c='black', alpha=0.1, ylim=(0,1), xlim=(0,700), s=3)\n",
    "data[data.is_tstp].plot.scatter('termset', 'inv_compression_ratio', ax=axes[1],\n",
    "                                c='black', alpha=0.1, ylim=(0,1), xlim=(0,700), s=3)\n",
    "axes[0].set_ylabel('Compression ratio')\n",
    "axes[1].set_ylabel('')\n",
    "for i in range(2): axes[i].set_xlabel('Termset size')\n",
    "axes[0].set_title('Lemma was generated')\n",
    "axes[1].set_title('All proofs')\n",
    "for ax in axes: ax.set_rasterized(True)\n",
    "plt.savefig('ratio_scatter.pdf', rasterized=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.is_tstp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
