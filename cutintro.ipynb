{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import lzma\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getData(file):\n",
    "    if file.endswith('.xz'): file = lzma.open(file, 'rt')\n",
    "    data = pd.read_json(file)\n",
    "    data = data.sort_values(['file', 'method'])\n",
    "    \n",
    "    # Adding a column for the database\n",
    "    data['db'] = -1 + \\\n",
    "        (0+1)*data.file.str.endswith(')') + \\\n",
    "        (1+1)*data.file.str.contains('/Prover9--') + \\\n",
    "        (2+1)*data.file.str.contains('/E---1') + \\\n",
    "        (3+1)*data.file.str.contains('/leanCoP--') + \\\n",
    "        (4+1)*data.file.str.contains('/QF_UF/')\n",
    "    \n",
    "    data['status'] = data.status.fillna(\"timeout_\" + data.phase)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"latest_results.json.xz\"\n",
    "data = None\n",
    "data = getData(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Other exceptions (aka bugs to hunt)\n",
    "\n",
    "data_other_exp = data[data.status == 'cutintro_other_exception']\n",
    "data_other_exp[['method', 'file', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test that fail for 1_dtable and are ok in 1_maxsat\n",
    "\n",
    "merged = pd.merge(\n",
    "    data[data.method == '1_dtable'],\n",
    "    data[data.method == '1_maxsat'],\n",
    "    on=['file'], suffixes=('_dtable', '_maxsat'))\n",
    "\n",
    "merged[(merged.status_maxsat == 'ok') & (merged.status_dtable != 'ok')][['file', 'status_dtable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test that are ok in 1_dtable and fail for 1_maxsat\n",
    "\n",
    "merged = pd.merge(\n",
    "    data[data.method == '1_dtable'],\n",
    "    data[data.method == '1_maxsat'],\n",
    "    on=['file'], suffixes=('_dtable', '_maxsat'))\n",
    "\n",
    "merged[(merged.status_maxsat != 'ok') & (merged.status_dtable == 'ok')][['file', 'status_maxsat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods = sorted(set(data.method.dropna()))\n",
    "\n",
    "dbs = {\n",
    "    0: 'Proof examples',\n",
    "    1: 'Prover9',\n",
    "    2: 'E',\n",
    "    3: 'LeanCoP',\n",
    "    4: 'VeriT',\n",
    "}\n",
    "\n",
    "dbs = { i: dbs[i] for i in dbs.keys() if i in data.db.values }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"=== Number of tests per database and method:\\n\")\n",
    "\n",
    "for dbi, dbname in dbs.items():\n",
    "    for method in methods:\n",
    "        print(\"{0} - {1}: {2}\".format(dbname, method,\n",
    "                                     data[(data.method==method) & (data.db==dbi)].shape[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = set(data.status.values)\n",
    "status_colors = {}\n",
    "for s in states:\n",
    "    if s == 'ok':\n",
    "        c = 'green'\n",
    "    elif s == 'cutintro_uncompressible':\n",
    "        c = 'yellow'\n",
    "    elif s == 'cutintro_termset_trivial':\n",
    "        c = 'gold'\n",
    "    elif 'timeout' in s:\n",
    "        c = plt.cm.Blues(hash(s)/2**65+0.5)\n",
    "    elif s.endswith('exception'):\n",
    "        c = plt.cm.Reds(hash(s)/2**65+0.5)\n",
    "    else:\n",
    "        c = plt.cm.Greys(hash(s)/2**65+0.5)\n",
    "    status_colors[s] = c\n",
    "\n",
    "def plot_status(d, legend=True, **kwargs):\n",
    "    plt.axis('equal')\n",
    "    d.plot(kind='pie', autopct='%1.1f%%',\n",
    "                        colors=[status_colors[s] for s in d.index], **kwargs) \\\n",
    "        .set_ylabel('')\n",
    "    if legend: plt.legend(d.index, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_status(data.groupby('status').size(), figsize=(14,12), title='Return status: full set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xsize, ysize = len(dbs.items()), len(methods)\n",
    "plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "plt.suptitle('Status per method and db', fontsize=25)\n",
    "for j, (dbi, db) in enumerate(dbs.items()):\n",
    "    for i, method in enumerate(methods):\n",
    "        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "        subdata = data[(data.db==dbi) & (data.method==method)].groupby('status').size()\n",
    "        plot_status(subdata, title='{0}\\n{1}'.format(db,method), labels=None, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timecols = ['time_grammar', 'time_minsol', 'time_prcons', 'time_cleanproof']\n",
    "plt.axis('equal')\n",
    "data[timecols].mean().plot(kind='pie', figsize=(12,12), autopct='%1.1f%%',\n",
    "                           title='Time: full set', legend=True).set_ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xsize, ysize = len(dbs.items()), len(methods)\n",
    "plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "plt.suptitle('Time consumption per method and db', fontsize=25)\n",
    "for i, method in enumerate(methods):\n",
    "    for j, (dbi, db) in enumerate(dbs.items()):\n",
    "        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "        plt.axis('equal')\n",
    "        data[(data.db==dbi) & (data.method==method)][timecols].mean() \\\n",
    "            .plot(kind='pie', autopct='%1.1f%%', labels=None,\n",
    "                  title='{0}\\n{1}'.format(db,method)).set_ylabel('')\n",
    "plt.legend(timecols, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xsize, ysize = len(dbs.items()), len(methods)\n",
    "plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "plt.suptitle('Time consumption per method and db, state==ok', fontsize=25)\n",
    "for i, method in enumerate(methods):\n",
    "    for j, (dbi, db) in enumerate(dbs.items()):\n",
    "        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "        plt.axis('equal')\n",
    "        ax = data[(data.db==dbi) & (data.method==method) & (data.status=='ok')][timecols].mean() \\\n",
    "            .plot(kind='pie', autopct='%1.1f%%', labels=None,\n",
    "                  title='{0}\\n{1}'.format(db,method))\n",
    "        ax.set_ylabel('')\n",
    "plt.legend(timecols, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different grammar sizes between different methods: one cut with one quantifier\n",
    "data_dtable = data[(data.method == '1_dtable') & data.grammar_size]\n",
    "data_maxsat = data[(data.method == '1_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = pd.merge(data_dtable, data_maxsat, on=['file'], suffixes=('_dtable', '_maxsat'))\n",
    "merged[merged.grammar_size_dtable != merged.grammar_size_maxsat] \\\n",
    "    [['file', 'grammar_size_dtable', 'grammar_size_maxsat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different grammar sizes between different methods: one cut with multiple quantifiers\n",
    "data_dtable = data[(data.method == 'many_dtable') & data.grammar_size]\n",
    "data_maxsat = data[(data.method == '2_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = pd.merge(data_dtable, data_maxsat, on=['file'], suffixes=('_dtable', '_maxsat'))\n",
    "merged[merged.grammar_size_dtable != merged.grammar_size_maxsat] \\\n",
    "    [['file', 'grammar_size_dtable', 'grammar_size_maxsat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Better compression with 2x2 quantifiers than 1x2 quantifiers or 2x1 quantifiers\n",
    "data_1x2 = data[(data.method == '2_maxsat') & data.grammar_size]\n",
    "data_2x1 = data[(data.method == '1_1_maxsat') & data.grammar_size]\n",
    "data_2x2 = data[(data.method == '2_2_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = data_1x2.merge(data_2x1, on='file', suffixes=('_1x2', '_2x1')) \\\n",
    "    .merge(data_2x2, on='file')\n",
    "merged[(merged.grammar_size < merged.grammar_size_1x2) & (merged.grammar_size < merged.grammar_size_2x1)] \\\n",
    "    [['file', 'grammar_size', 'grammar_size_2x1', 'grammar_size_1x2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['is_smaller'] = (data.status=='ok') & (data.ehs_resinf < data.resinf_input)\n",
    "data['is_larger'] = (data.status=='ok') & (data.ehs_resinf >= data.resinf_input)\n",
    "data['is_trivial'] = data.status.str.endswith('termset_trivial')\n",
    "data['is_uncompressible'] = data.status.str.endswith('uncompressible')\n",
    "data['is_timeout'] = data.status.str.endswith('timeout')\n",
    "data['is_error'] = ~data.is_smaller & ~data.is_larger & ~data.is_trivial & ~data.is_uncompressible & ~data.is_timeout\n",
    "\n",
    "data[(data.termset<65)&(data.db==1)].groupby('termset').mean() \\\n",
    "    [['is_trivial', 'is_uncompressible', 'is_larger', 'is_smaller', 'is_timeout', 'is_error']] \\\n",
    "    .plot(kind='area', figsize=(16,12), ylim=(0,1), title='Status by termset size (prover9)',\n",
    "          color=['gold', 'yellow', 'lime', 'green', 'royalblue', 'tomato'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proofs with good compression of EHS/HS\n",
    "data[data.ehs_resinf/data.hs_resinf < 0.2] \\\n",
    "    [['file', 'method', 'ehs_resinf', 'hs_resinf', 'resinf_input']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proofs with good compression of EHS/input\n",
    "data[data.ehs_resinf/data.resinf_input < 0.2] \\\n",
    "    [['file', 'method', 'ehs_resinf', 'hs_resinf', 'resinf_input']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proofs with blowup\n",
    "data[data.ehs_resinf > 5*data.hs_resinf] \\\n",
    "    [['file', 'method', 'ehs_resinf', 'hs_resinf', 'resinf_input']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = (data.time_maxsat/data.time_grammar).dropna().plot(kind='hist', figsize=(14,8),\n",
    "    title='Percentage of grammar finding time spent in MaxSAT solver', bins=20)\n",
    "ax.set_xlabel('percentage')\n",
    "ax.set_ylabel('number of testcases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "for method in methods:\n",
    "    plt.plot(data[(data.method==method)&\n",
    "                  (data.grammar_size>0)&\n",
    "                  (data.grammar_size<0.75*data.termset)&\n",
    "                  (data.termset_trivial==False)&\n",
    "                  (data.file.str.contains('Solution'))\n",
    "                 ].time_grammar.sort_values().values / 1000,\n",
    "             label=method)\n",
    "plt.xlabel('number of compressed term sets')\n",
    "plt.ylabel('CPU runtime (seconds)')\n",
    "plt.ylim(0,10)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
