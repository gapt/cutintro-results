{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import lzma\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.max_rows = 1000\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = \"results.json.xz\"\n",
    "\n",
    "data = None\n",
    "if file.endswith('.xz'): file = lzma.open(file, 'rt')\n",
    "data = pd.read_json(file)\n",
    "data = data.sort_values(['file', 'method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a column for the database\n",
    "data['db'] = -1 + \\\n",
    "    (0+1)*data.file.str.endswith(')') + \\\n",
    "    (1+1)*data.file.str.contains('/Prover9--') + \\\n",
    "    (2+1)*data.file.str.contains('/Vampire---4.0') + \\\n",
    "    (3+1)*data.file.str.contains('/leanCoP--') + \\\n",
    "    (4+1)*data.file.str.contains('/QF_UF/')\n",
    "    \n",
    "data['status'] = data.status.fillna(\"timeout_\" + data.phase)\n",
    "\n",
    "data['is_smaller'] = (data.status=='ok') & (data.ehs_resinf < data.resinf_input)\n",
    "data['is_larger'] = (data.status=='ok') & (data.ehs_resinf >= data.resinf_input)\n",
    "data['is_trivial'] = data.status.str.endswith('termset_trivial')\n",
    "data['is_uncompressible'] = data.status.str.endswith('uncompressible')\n",
    "data['is_timeout'] = data.status.str.startswith('timeout')\n",
    "data['is_error'] = ~data.is_smaller & ~data.is_larger & ~data.is_trivial & ~data.is_uncompressible & ~data.is_timeout\n",
    "\n",
    "data['tstp_cat'] = data.file.str.extract('/([A-Z]{3,3})/', expand=False)\n",
    "data['is_tstp'] = data.tstp_cat.notnull()\n",
    "\n",
    "data['compression_ratio'] = data.termset/data.grammar_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Other exceptions (aka bugs to hunt)\n",
    "\n",
    "data_other_exp = data[(data.status == 'cutintro_other_exception')]\n",
    "data_other_exp[['method', 'file', 'status']].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods = sorted(set(data.method.dropna()))\n",
    "\n",
    "dbs = {\n",
    "    0: 'Proof examples',\n",
    "    1: 'Prover9',\n",
    "    2: 'Vampire',\n",
    "    3: 'LeanCoP',\n",
    "    4: 'VeriT',\n",
    "}\n",
    "\n",
    "dbs = { i: dbs[i] for i in dbs.keys() if i in data.db.values }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"=== Number of tests per database and method:\\n\")\n",
    "\n",
    "#for dbi, dbname in dbs.items():\n",
    "#    for method in methods:\n",
    "#        print(\"{0} - {1}: {2}\".format(dbname, method,\n",
    "#                                     data[(data.method==method) & (data.db==dbi)].shape[0]))\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = set(data.status.values)\n",
    "status_colors = {}\n",
    "for s in states:\n",
    "    if s == 'ok':\n",
    "        c = 'green'\n",
    "    elif s == 'cutintro_uncompressible':\n",
    "        c = 'yellow'\n",
    "    elif s == 'cutintro_termset_trivial':\n",
    "        c = 'gold'\n",
    "    elif 'timeout' in s:\n",
    "        c = plt.cm.Blues(hash(s)/2**65+0.5)\n",
    "    elif s.endswith('exception'):\n",
    "        c = plt.cm.Reds(hash(s)/2**65+0.5)\n",
    "    else:\n",
    "        c = plt.cm.Greys(hash(s)/2**65+0.5)\n",
    "    status_colors[s] = c\n",
    "\n",
    "def plot_status(d, legend=True, **kwargs):\n",
    "    plt.axis('equal')\n",
    "    d.plot(kind='pie', autopct='%1.1f%%',\n",
    "                        colors=[status_colors[s] for s in d.index], **kwargs) \\\n",
    "        .set_ylabel('')\n",
    "    if legend: plt.legend(d.index, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_status(data.groupby('status').size(), figsize=(14,12), title='Return status: full set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xsize, ysize = len(dbs.items()), len(methods)\n",
    "plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "plt.suptitle('Status per method and db', fontsize=25)\n",
    "for j, (dbi, db) in enumerate(dbs.items()):\n",
    "    for i, method in enumerate(methods):\n",
    "        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "        subdata = data[(data.db==dbi) & (data.method==method)].groupby('status').size()\n",
    "        plot_status(subdata, title='{0}\\n{1}'.format(db,method), labels=None, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timecols = ['time_grammar', 'time_minsol', 'time_prcons', 'time_cleanproof']\n",
    "#plt.axis('equal')\n",
    "#data[timecols].mean().plot(kind='pie', figsize=(12,12), autopct='%1.1f%%',\n",
    "#                           title='Time: full set', legend=True).set_ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xsize, ysize = len(dbs.items()), len(methods)\n",
    "#plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "#plt.suptitle('Time consumption per method and db', fontsize=25)\n",
    "#for i, method in enumerate(methods):\n",
    "#    for j, (dbi, db) in enumerate(dbs.items()):\n",
    "#        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "#        plt.axis('equal')\n",
    "#        data[(data.db==dbi) & (data.method==method)][timecols].mean() \\\n",
    "#            .plot(kind='pie', autopct='%1.1f%%', labels=None,\n",
    "#                  title='{0}\\n{1}'.format(db,method)).set_ylabel('')\n",
    "#plt.legend(timecols, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xsize, ysize = len(dbs.items()), len(methods)\n",
    "#plt.figure(1, figsize=(3*xsize,4*ysize))\n",
    "#plt.suptitle('Time consumption per method and db, state==ok', fontsize=25)\n",
    "#for i, method in enumerate(methods):\n",
    "#    for j, (dbi, db) in enumerate(dbs.items()):\n",
    "#        plt.subplot(ysize, xsize, i*xsize + j + 1)\n",
    "#        plt.axis('equal')\n",
    "#        ax = data[(data.db==dbi) & (data.method==method) & (data.status=='ok')][timecols].mean() \\\n",
    "#            .plot(kind='pie', autopct='%1.1f%%', labels=None,\n",
    "#                  title='{0}\\n{1}'.format(db,method))\n",
    "#        ax.set_ylabel('')\n",
    "#plt.legend(timecols, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different grammar sizes between different methods: one cut with one quantifier\n",
    "data_dtable = data[(data.method == '1_dtable') & data.grammar_size]\n",
    "data_maxsat = data[(data.method == '1_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = pd.merge(data_dtable, data_maxsat, on=['file'], suffixes=('_dtable', '_maxsat'))\n",
    "merged[merged.grammar_size_dtable != merged.grammar_size_maxsat] \\\n",
    "    [['file', 'grammar_size_dtable', 'grammar_size_maxsat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different grammar sizes between different methods: one cut with multiple quantifiers\n",
    "data_dtable = data[(data.method == 'many_dtable') & data.grammar_size]\n",
    "data_maxsat = data[(data.method == '2_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = pd.merge(data_dtable, data_maxsat, on=['file'], suffixes=('_dtable', '_maxsat'))\n",
    "merged[merged.grammar_size_dtable != merged.grammar_size_maxsat] \\\n",
    "    [['file', 'grammar_size_dtable', 'grammar_size_maxsat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Better compression with 2x2 quantifiers than 1x2 quantifiers or 2x1 quantifiers\n",
    "data_1x2 = data[(data.method == '2_maxsat') & data.grammar_size]\n",
    "data_2x1 = data[(data.method == '1_1_maxsat') & data.grammar_size]\n",
    "data_2x2 = data[(data.method == '2_2_maxsat') & data.grammar_size]\n",
    "\n",
    "merged = data_1x2.merge(data_2x1, on='file', suffixes=('_1x2', '_2x1')) \\\n",
    "    .merge(data_2x2, on='file')\n",
    "merged[(merged.grammar_size < merged.grammar_size_1x2) & (merged.grammar_size < merged.grammar_size_2x1)] \\\n",
    "    [['file', 'grammar_size', 'grammar_size_2x1', 'grammar_size_1x2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[(data.termset<65)&data.is_tstp&(data.method=='many_dtable_ss')].groupby('termset').mean() \\\n",
    "    [['is_trivial', 'is_uncompressible', 'is_smaller', 'is_larger', 'is_timeout', 'is_error']] \\\n",
    "    .plot(kind='area', figsize=(16,12), ylim=(0,1),\n",
    "          title='Status by termset size for the delta-table with many variables',\n",
    "          color=['gold', 'yellow', 'green', 'lime', 'royalblue', 'tomato'])\n",
    "plt.savefig('status_by_termset.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proofs with good compression of EHS/HS\n",
    "data[data.ehs_resinf/data.hs_resinf < 0.2] \\\n",
    "    [['file', 'method', 'ehs_resinf', 'hs_resinf', 'resinf_input', 'beausol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proofs with good compression of EHS/input\n",
    "data[data.ehs_resinf/data.resinf_input < 0.2] \\\n",
    "    [['file', 'method', 'ehs_resinf', 'hs_resinf', 'resinf_input', 'beausol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proofs with blowup\n",
    "data[data.ehs_resinf > 5*data.hs_resinf] \\\n",
    "    [['file', 'method', 'ehs_resinf', 'hs_resinf', 'resinf_input']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cactus plot for grammar finding methods\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "tstp_dataset = \\\n",
    "    (data.grammar_size>0)& \\\n",
    "    data.beausol& \\\n",
    "    data.is_tstp\n",
    "for method in sorted(set(data[tstp_dataset].method),\n",
    "                     key = lambda m: len(data[tstp_dataset&(data.method==m)&(data.time_grammar<5000)])):\n",
    "    plt.plot(\n",
    "        data[(data.method==method)&tstp_dataset].\n",
    "            time_grammar.sort_values().values / 1000,\n",
    "        label=method)\n",
    "\n",
    "virtual_best = data[tstp_dataset].groupby('file').time_grammar.min()\n",
    "plt.plot(virtual_best.sort_values().values / 1000, label='virtual best', color='black')\n",
    "\n",
    "plt.xlabel('number of grammars that lead to a non-trivial lemma')\n",
    "plt.ylabel('CPU runtime of grammar generation (seconds)')\n",
    "plt.ylim(0,5)\n",
    "plt.legend(loc='upper right', framealpha=0.7)\n",
    "plt.savefig('grammar_finding_cactus.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[(data.beausol_scomp < 100) &\n",
    "     (data.beausol_lcomp > 3) &\n",
    "     (data.beausol_scomp > 1) &\n",
    "     (data.time_total > 30000) &\n",
    "     data.is_tstp &\n",
    "     ~data.file.str.contains('SY')] \\\n",
    "    .sort_values('beausol_scomp')[['file', 'method', 'beausol', 'time_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "tstp_success = data[data.is_tstp&data.beausol]\n",
    "(tstp_success.minsol_scomp/tstp_success.cansol_scomp).plot.kde(label='minimized')\n",
    "(tstp_success.beausol_scomp/tstp_success.cansol_scomp).plot.kde(label='beautified')\n",
    "plt.legend()\n",
    "plt.xlim(0,1)\n",
    "plt.ylabel('Estimated density')\n",
    "plt.xlabel('Ratio of symbolic complexity compared to canonical solution')\n",
    "plt.savefig('improvement_comp_density.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Added productions during beautification\n",
    "tstp_success = data[data.is_tstp&data.beausol]\n",
    "(tstp_success.beaugrammar_size-tstp_success.grammar_size).describe(percentiles = [.25, .5, .75, .80, .85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "tstp_ok = data[data.is_tstp&(data.status=='ok')&data.resinf_input]\n",
    "(tstp_ok.resinf_input/tstp_ok.hs_resinf).plot.kde(label='input proof')\n",
    "(tstp_ok.ehs_resinf/tstp_ok.hs_resinf).plot.kde(label='proof of EHS')\n",
    "plt.legend()\n",
    "plt.xlim(0,3)\n",
    "plt.ylabel('Estimated density')\n",
    "plt.xlabel('Ratio of number of inferences compared to proof of HS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.is_tstp&data.beausol&(data.method!='reforest')].plot.scatter('termset', 'compression_ratio',\n",
    "                          alpha=0.2, figsize=(14,8))\n",
    "plt.xlim(0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "data[data.is_tstp&data.beausol&(data.method!='reforest')].compression_ratio.plot.kde()\n",
    "plt.xlabel('Size of grammar / size of term set')\n",
    "plt.xlim(0.5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of proofs in TSTP library\n",
    "num_tstp = len(set(data[data.is_tstp].file)); num_tstp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of proofs we can parse\n",
    "num_tstp_parsed = len(set(data[data.is_tstp&data.termset].file)); num_tstp_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of trivial termsets\n",
    "num_trivial = len(set(data[data.is_tstp&data.termset_trivial].file)); num_trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of non-trivial termsets\n",
    "num_nontrivial = len(set(data[data.is_tstp&(data.termset_trivial==False)].file)); num_nontrivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of grammars generated\n",
    "num_grammar_gen = len(set(data[data.is_tstp&data.grammar_size].file)); num_grammar_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of lemmas generated\n",
    "num_lemmas_gen = len(set(data[data.is_tstp&data.beausol].file)); num_lemmas_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solutions for trivial termsets\n",
    "data[data.is_tstp &\n",
    "     data.termset_trivial &\n",
    "     (data.grammar_size>0) &\n",
    "     (data.beausol_scomp<10) &\n",
    "     (data.beausol_scomp>1)\n",
    "    ][['file', 'beausol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of proofs with trivial termsets where we found a grammar\n",
    "len(set(data[data.is_tstp&data.termset_trivial&(data.grammar_size>0)].file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Size of canonical solution vs grammar size\n",
    "tstp_success = data[data.is_tstp&data.beausol]\n",
    "tstp_success.plot.scatter('cansol_lcomp', 'grammar_size', figsize=(14,8), alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.status=='cutintro_noncovering_grammar'][['file','method']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
